{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatch™, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-13 21:22:58.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\tycoh\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:47<00:00, 55.15it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:11<00:00, 55.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 34, 3]),\n",
       " tensor([ 9, 10, 14,  7, 13, 16, 12, 11, 19, 17,  5,  0, 15, 16, 14, 19, 12, 14,\n",
       "          7, 17,  5,  9, 14,  9, 11,  6, 17,  3,  7, 11,  5,  3]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "What does it mean that the shapes are sometimes (32, 27, 3), but a second time might look like (32, 30, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? How does the model handle this? Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "- So it is 32 batches, 37 timesteps and 3 features or it could be 32 batches 30 timesteps and 3 features. The variance in timesteps depends on the length of the gesture. The model cannot handle this so therefore you need padding in order to have all the same size of timesteps.\n",
    "\n",
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn_models.BaseRNN(\n",
    "    input_size=3,\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    horizon=20,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!\n",
    "- We need a 2D output tensor because we want to classify the gestures and a fully connected layers needs a 2D shape (batches and class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "- This is a very bad accuracy, only 9% of the time it is correct. I would expect an accuracy of 1/20 from blind guessing.\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 20]), torch.Size([32]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0323, -0.1437,  0.1171,  0.1633,  0.0516, -0.0692, -0.1154, -0.0357,\n",
       "         0.0878,  0.0021, -0.0021,  0.2095, -0.0472, -0.1498, -0.0840,  0.0021,\n",
       "        -0.0688,  0.0677, -0.0335,  0.0426], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03790000000000001"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([-0.0323, -0.1437,  0.1171,  0.1633,  0.0516, -0.0692, -0.1154, -0.0357,\n",
    "    0.0878,  0.0021, -0.0021,  0.2095, -0.0472, -0.1498, -0.0840,  0.0021,\n",
    "    -0.0688,  0.0677, -0.0335,  0.0426])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "- No, because they don't sum to 1. It has to be 1 of the 20 classes so together the predicted values should be 1.\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0137, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 20\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: {'save': False, 'verbose': True, 'patience': 5, 'delta': 0.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=20, # increase this to about 100 for training\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": False, # save every best model, and restore the best one\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "        \"delta\": 0.0, # minimum change to be considered an improvement\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 16:21:02.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251014-162102\u001b[0m\n",
      "\u001b[32m2025-10-14 16:21:02.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:05<00:00,  1.23it/s]\n",
      "\u001b[32m2025-10-14 16:22:15.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.1949 test 1.5590 metric ['0.4437']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:28<00:00,  1.09s/it]\n",
      "\u001b[32m2025-10-14 16:23:50.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.0355 test 0.6412 metric ['0.8141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:59<00:00,  1.36it/s]\n",
      "\u001b[32m2025-10-14 16:24:53.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3547 test 0.2684 metric ['0.9250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:56<00:00,  1.44it/s]\n",
      "\u001b[32m2025-10-14 16:25:53.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1184 test 0.1734 metric ['0.9516']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:56<00:00,  1.44it/s]\n",
      "\u001b[32m2025-10-14 16:26:53.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0767 test 0.3129 metric ['0.9109']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:26:53.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1734, current loss 0.3129.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:58<00:00,  1.39it/s]\n",
      "\u001b[32m2025-10-14 16:27:55.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0769 test 0.1448 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:55<00:00,  1.46it/s]\n",
      "\u001b[32m2025-10-14 16:28:55.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0431 test 0.1512 metric ['0.9594']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:28:55.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1448, current loss 0.1512.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:55<00:00,  1.46it/s]\n",
      "\u001b[32m2025-10-14 16:29:54.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0442 test 0.1492 metric ['0.9641']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:29:54.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1448, current loss 0.1492.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:54<00:00,  1.48it/s]\n",
      "\u001b[32m2025-10-14 16:30:52.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0474 test 0.0553 metric ['0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:57<00:00,  1.42it/s]\n",
      "\u001b[32m2025-10-14 16:31:51.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0204 test 0.0505 metric ['0.9891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:13<00:00,  1.10it/s]\n",
      "\u001b[32m2025-10-14 16:33:12.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0202 test 0.0726 metric ['0.9828']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:33:12.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0505, current loss 0.0726.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:04<00:00,  1.26it/s]\n",
      "\u001b[32m2025-10-14 16:34:18.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0232 test 0.1046 metric ['0.9781']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:34:18.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0505, current loss 0.1046.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:57<00:00,  1.41it/s]\n",
      "\u001b[32m2025-10-14 16:35:20.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0129 test 0.0861 metric ['0.9812']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:35:20.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0505, current loss 0.0861.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:10<00:00,  1.14it/s]\n",
      "\u001b[32m2025-10-14 16:36:37.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0036 test 0.0585 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:36:37.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0505, current loss 0.0585.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:29<00:00,  1.11s/it]\n",
      "\u001b[32m2025-10-14 16:38:14.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0011 test 0.0538 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-10-14 16:38:14.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0505, current loss 0.0538.Counter 5/5.\u001b[0m\n",
      "\u001b[32m2025-10-14 16:38:14.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-10-14 16:38:14.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mearly_stopping_save was false, using latest model.Set to true to retrieve best model.\u001b[0m\n",
      " 70%|\u001b[38;2;30;71;6m███████   \u001b[0m| 14/20 [17:11<07:22, 73.67s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"gru-gestures_experiment_layers4_units512_epochs50\")\n",
    "    mlflow.set_tag(\"dev\", \"tyco\")\n",
    "    config = ModelConfig(\n",
    "        input_size=3,\n",
    "        hidden_size=512,\n",
    "        num_layers=4,\n",
    "        output_size=20,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "\n",
    "    model = GRUmodel(\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    if not settings.earlystop_kwargs[\"save\"]:\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to update the code above by changing the hyperparameters.\n",
    "- after testing with 3 epochs it looks like the best results happen with a not to deep (4 layers) and wider (512) network. After seeing this - I decided to crank up to epochs to 50 to see if further improvement of difficult patterns helps.\n",
    "    \n",
    "To discern between the changes, also modify the tag mlflow.set_tag(\"model\", \"new-tag-here\") where you add\n",
    "a new tag of your choice. This way you can keep the models apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 35.44it/s]\n",
      "\u001b[32m2025-10-13 21:24:14.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mResuming epochs from previous training at 3\u001b[0m\n",
      "\u001b[32m2025-10-13 21:24:15.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 1.9470 test 1.8368 metric ['0.3359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 33.93it/s]\n",
      "\u001b[32m2025-10-13 21:24:17.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 1.7459 test 1.6587 metric ['0.4672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 41.21it/s]\n",
      "\u001b[32m2025-10-13 21:24:19.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 1.5600 test 1.4342 metric ['0.5203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:07<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.loop() # if you want to pick up training, loop will continue from the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-15 17:36:45.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251015-173645\u001b[0m\n",
      "\u001b[32m2025-10-15 17:36:45.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:47<00:00,  1.69it/s]\n",
      "\u001b[32m2025-10-15 17:37:45.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.5746 test 2.4262 metric ['0.1313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:31<00:00,  1.13s/it]\n",
      "\u001b[32m2025-10-15 17:39:19.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 2.2409 test 2.1812 metric ['0.2687']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:39<00:00,  2.06it/s]\n",
      "\u001b[32m2025-10-15 17:40:00.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 2.0486 test 2.7735 metric ['0.2437']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:40:00.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 2.1812, current loss 2.7735.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:34<00:00,  2.38it/s]\n",
      "\u001b[32m2025-10-15 17:40:36.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 2.0384 test 1.7953 metric ['0.3141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:59<00:00,  1.35it/s]\n",
      "\u001b[32m2025-10-15 17:41:38.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 1.6952 test 2.1981 metric ['0.2469']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:41:38.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 1.7953, current loss 2.1981.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:38<00:00,  2.09it/s]\n",
      "\u001b[32m2025-10-15 17:42:18.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 1.5247 test 1.4385 metric ['0.3766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:35<00:00,  2.29it/s]\n",
      "\u001b[32m2025-10-15 17:42:55.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 1.2627 test 1.1623 metric ['0.4734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:35<00:00,  2.29it/s]\n",
      "\u001b[32m2025-10-15 17:43:32.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 1.1364 test 1.2372 metric ['0.4672']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:43:32.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 1.1623, current loss 1.2372.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:32<00:00,  2.53it/s]\n",
      "\u001b[32m2025-10-15 17:44:06.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 1.0155 test 0.9965 metric ['0.5609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:31<00:00,  2.60it/s]\n",
      "\u001b[32m2025-10-15 17:44:38.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.8571 test 0.9640 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:51<00:00,  1.57it/s]\n",
      "\u001b[32m2025-10-15 17:45:40.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.8715 test 0.9335 metric ['0.6281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:35<00:00,  1.18s/it]\n",
      "\u001b[32m2025-10-15 17:47:18.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.6293 test 0.6296 metric ['0.7531']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:35<00:00,  2.25it/s]\n",
      "\u001b[32m2025-10-15 17:47:55.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.5396 test 0.4492 metric ['0.8562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:30<00:00,  2.69it/s]\n",
      "\u001b[32m2025-10-15 17:48:27.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.3540 test 0.4688 metric ['0.8438']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:48:27.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.4492, current loss 0.4688.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:30<00:00,  2.64it/s]\n",
      "\u001b[32m2025-10-15 17:49:00.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.2592 test 0.2712 metric ['0.9266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:33<00:00,  2.40it/s]\n",
      "\u001b[32m2025-10-15 17:49:35.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.1675 test 0.3773 metric ['0.8828']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:49:35.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2712, current loss 0.3773.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:33<00:00,  2.42it/s]\n",
      "\u001b[32m2025-10-15 17:50:11.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 16 train 0.1418 test 0.1541 metric ['0.9625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:35<00:00,  2.26it/s]\n",
      "\u001b[32m2025-10-15 17:50:48.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 17 train 0.0936 test 0.1658 metric ['0.9609']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:50:48.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1541, current loss 0.1658.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:31<00:00,  2.58it/s]\n",
      "\u001b[32m2025-10-15 17:51:21.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 18 train 0.1985 test 0.3143 metric ['0.9219']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:51:21.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1541, current loss 0.3143.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:33<00:00,  2.41it/s]\n",
      "\u001b[32m2025-10-15 17:51:57.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 19 train 0.1810 test 0.1918 metric ['0.9437']\u001b[0m\n",
      "\u001b[32m2025-10-15 17:51:57.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1541, current loss 0.1918.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 20/20 [15:11<00:00, 45.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"lstm-gestures_experiment_layers4_units512_epochs20\")\n",
    "    mlflow.set_tag(\"dev\", \"tyco\")\n",
    "    config = ModelConfig(\n",
    "        input_size=3,\n",
    "        hidden_size=512,\n",
    "        num_layers=4,\n",
    "        output_size=20,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "\n",
    "    model = LSTMmodel(\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    if not settings.earlystop_kwargs[\"save\"]:\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another Rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-15 20:22:40.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures\\20251015-202240\u001b[0m\n",
      "\u001b[32m2025-10-15 20:22:40.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:59<00:00,  1.36it/s]\n",
      "\u001b[32m2025-10-15 20:23:44.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.1427 test 1.3564 metric ['0.5422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:00<00:00,  1.34it/s]\n",
      "\u001b[32m2025-10-15 20:24:49.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.8122 test 0.5733 metric ['0.8547']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:00<00:00,  1.33it/s]\n",
      "\u001b[32m2025-10-15 20:25:58.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5179 test 0.3336 metric ['0.9125']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:46<00:00,  1.32s/it]\n",
      "\u001b[32m2025-10-15 20:27:49.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1866 test 0.1380 metric ['0.9688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [01:07<00:00,  1.21it/s]\n",
      "\u001b[32m2025-10-15 20:29:01.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0777 test 0.1965 metric ['0.9641']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:29:01.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.1380, current loss 0.1965.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:43<00:00,  1.85it/s]\n",
      "\u001b[32m2025-10-15 20:29:48.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0636 test 0.0943 metric ['0.9766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:39<00:00,  2.04it/s]\n",
      "\u001b[32m2025-10-15 20:30:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0443 test 0.0960 metric ['0.9844']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:30:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0943, current loss 0.0960.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:39<00:00,  2.07it/s]\n",
      "\u001b[32m2025-10-15 20:31:12.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.1921 test 0.1993 metric ['0.9578']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:31:12.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0943, current loss 0.1993.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:50<00:00,  1.62it/s]\n",
      "\u001b[32m2025-10-15 20:32:05.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.1632 test 0.1699 metric ['0.9641']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:32:05.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0943, current loss 0.1699.Counter 3/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:51<00:00,  1.58it/s]\n",
      "\u001b[32m2025-10-15 20:32:58.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0783 test 0.1240 metric ['0.9672']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:32:58.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0943, current loss 0.1240.Counter 4/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:48<00:00,  1.68it/s]\n",
      "\u001b[32m2025-10-15 20:33:50.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.1395 test 0.5178 metric ['0.9250']\u001b[0m\n",
      "\u001b[32m2025-10-15 20:33:50.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0943, current loss 0.5178.Counter 5/5.\u001b[0m\n",
      "\u001b[32m2025-10-15 20:33:50.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-10-15 20:33:50.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mearly_stopping_save was false, using latest model.Set to true to retrieve best model.\u001b[0m\n",
      " 50%|\u001b[38;2;30;71;6m█████     \u001b[0m| 10/20 [11:09<11:09, 66.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "from mltrainer.rnn_models import AttentionGRU\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"gruAttention-gestures_experiment_layers4_units512_epochs20\")\n",
    "    mlflow.set_tag(\"dev\", \"tyco\")\n",
    "    config = ModelConfig(\n",
    "        input_size=3,\n",
    "        hidden_size=512,\n",
    "        num_layers=4,\n",
    "        output_size=20,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "\n",
    "    model = AttentionGRU(\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    if not settings.earlystop_kwargs[\"save\"]:\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with conv1d layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
