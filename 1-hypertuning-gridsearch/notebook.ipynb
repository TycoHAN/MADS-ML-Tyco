{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 16:43:17.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\tycoh\\.cache\\mads_datasets\\fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-20 16:43:17.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at C:\\Users\\tycoh\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps= 100,\n",
    "    valid_steps= 100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments.\n",
    "\n",
    "This package will 1. check if there is a `__dict__` attribute available, and if so, it will use that to extract the parameters that do not start with an underscore, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True, 'num_classes': 10, 'units1': 256, 'units2': 256}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in model.__dict__.items() if not k.startswith(\"_\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if you want to add more parameters to the `.toml` file, eg `units3`, you can add them to the class like this:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3  # <-- add this line\n",
    "```\n",
    "\n",
    "And then it will be added to the `.toml` file. Check the result for yourself by using the `.save()` method of the `TomlSerializer` class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 16:43:17.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250920-164317\u001b[0m\n",
      "\u001b[32m2025-09-20 16:43:18.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 228.06it/s]\n",
      "\u001b[32m2025-09-20 16:43:19.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.9176 test 0.6248 metric ['0.7789']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 172.12it/s]\n",
      "\u001b[32m2025-09-20 16:43:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.5804 test 0.5523 metric ['0.7948']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 254.80it/s]\n",
      "\u001b[32m2025-09-20 16:43:20.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5135 test 0.5307 metric ['0.8086']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> because it doens't know what the best setting is it tries al possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 64, 256\n",
      "Random Units: 128, 128\n",
      "Random Units: 128, 256\n",
      "Random Units: 256, 128\n",
      "Random Units: 64, 256\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "units = [256, 128, 64]\n",
    "for _ in range(5):  \n",
    "    unit1 = random.choice(units)\n",
    "    unit2 = random.choice(units)\n",
    "    print(f\"Random Units: {unit1}, {unit2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 15:31:33.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250921-153133\u001b[0m\n",
      "\u001b[32m2025-09-21 15:31:33.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 256, 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:00<00:00, 134.28it/s]\n",
      "\u001b[32m2025-09-21 15:31:34.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.9495 test 0.6434 metric ['0.7637']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 107.38it/s]\n",
      "\u001b[32m2025-09-21 15:31:36.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.5664 test 0.5483 metric ['0.8048']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 124.31it/s]\n",
      "\u001b[32m2025-09-21 15:31:37.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5070 test 0.5162 metric ['0.8206']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 105.10it/s]\n",
      "\u001b[32m2025-09-21 15:31:39.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.4791 test 0.4813 metric ['0.8330']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 92.87it/s]\n",
      "\u001b[32m2025-09-21 15:31:41.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4700 test 0.4544 metric ['0.8400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.64s/it]\n",
      "\u001b[32m2025-09-21 15:31:41.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250921-153141\u001b[0m\n",
      "\u001b[32m2025-09-21 15:31:41.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 64, 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 123.62it/s]\n",
      "\u001b[32m2025-09-21 15:31:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.0491 test 0.6903 metric ['0.7509']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:00<00:00, 136.13it/s]\n",
      "\u001b[32m2025-09-21 15:31:44.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6088 test 0.5855 metric ['0.7847']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 103.70it/s]\n",
      "\u001b[32m2025-09-21 15:31:45.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5226 test 0.5443 metric ['0.8052']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 97.88it/s]\n",
      "\u001b[32m2025-09-21 15:31:47.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.4917 test 0.5064 metric ['0.8240']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 120.47it/s]\n",
      "\u001b[32m2025-09-21 15:31:49.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4703 test 0.4982 metric ['0.8119']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.58s/it]\n",
      "\u001b[32m2025-09-21 15:31:49.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250921-153149\u001b[0m\n",
      "\u001b[32m2025-09-21 15:31:49.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 64, 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 108.10it/s]\n",
      "\u001b[32m2025-09-21 15:31:50.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.0976 test 0.6966 metric ['0.7430']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 111.35it/s]\n",
      "\u001b[32m2025-09-21 15:31:52.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6425 test 0.5965 metric ['0.7793']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 121.31it/s]\n",
      "\u001b[32m2025-09-21 15:31:53.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5461 test 0.5295 metric ['0.8170']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:00<00:00, 145.35it/s]\n",
      "\u001b[32m2025-09-21 15:31:55.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.5155 test 0.5278 metric ['0.8163']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 108.50it/s]\n",
      "\u001b[32m2025-09-21 15:31:56.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4694 test 0.5375 metric ['0.8070']\u001b[0m\n",
      "\u001b[32m2025-09-21 15:31:56.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.5278, current loss 0.5375.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.54s/it]\n",
      "\u001b[32m2025-09-21 15:31:56.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250921-153156\u001b[0m\n",
      "\u001b[32m2025-09-21 15:31:56.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 64, 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 121.92it/s]\n",
      "\u001b[32m2025-09-21 15:31:58.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.1001 test 0.7259 metric ['0.7223']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 104.92it/s]\n",
      "\u001b[32m2025-09-21 15:32:00.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6333 test 0.6062 metric ['0.7875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 124.73it/s]\n",
      "\u001b[32m2025-09-21 15:32:01.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5478 test 0.5392 metric ['0.8027']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 104.20it/s]\n",
      "\u001b[32m2025-09-21 15:32:03.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.4991 test 0.5219 metric ['0.8136']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 108.37it/s]\n",
      "\u001b[32m2025-09-21 15:32:04.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.5008 test 0.4850 metric ['0.8298']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.62s/it]\n",
      "\u001b[32m2025-09-21 15:32:04.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20250921-153204\u001b[0m\n",
      "\u001b[32m2025-09-21 15:32:04.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Units: 64, 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 123.02it/s]\n",
      "\u001b[32m2025-09-21 15:32:06.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.0792 test 0.7149 metric ['0.7416']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:00<00:00, 130.63it/s]\n",
      "\u001b[32m2025-09-21 15:32:07.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.6204 test 0.6702 metric ['0.7667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:00<00:00, 130.72it/s]\n",
      "\u001b[32m2025-09-21 15:32:09.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5358 test 0.5376 metric ['0.8011']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 121.18it/s]\n",
      "\u001b[32m2025-09-21 15:32:10.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.5023 test 0.5562 metric ['0.7966']\u001b[0m\n",
      "\u001b[32m2025-09-21 15:32:10.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.5376, current loss 0.5562.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 128/128 [00:01<00:00, 112.09it/s]\n",
      "\u001b[32m2025-09-21 15:32:12.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4843 test 0.5121 metric ['0.8159']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "units = [1024,512,256]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=128,\n",
    "    valid_steps=128,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "units = [256, 128, 64]\n",
    "for _ in range(5):  \n",
    "    trainstreamer = train.stream()\n",
    "    validstreamer = valid.stream()\n",
    "    unit1 = random.choice(units)\n",
    "    unit2 = random.choice(units)\n",
    "    print(f\"Random Units: {unit1}, {unit2}\")\n",
    "    model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "    trainer.loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
