{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38738c5b",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fcf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import ReportTypes, Trainer, TrainerSettings, metrics, rnn_models\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fd3dc",
   "metadata": {},
   "source": [
    "Setting seeds for isolated testing, but doesnt fix all randomness unfortunately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ef1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1445640",
   "metadata": {},
   "source": [
    "Get flowers data into a streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705d3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-28 20:41:38.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\tycoh\\.cache\\mads_datasets\\fashionmnist\u001b[0m\n",
      "\u001b[32m2025-10-28 20:41:38.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at C:\\Users\\tycoh\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "fashion = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "batchsize = 64\n",
    "streamers = fashion.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers['train']\n",
    "valid = streamers['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b960b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b3d393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 2, 5, 8, 9, 7, 8, 5, 0, 8, 9, 4, 0, 4, 0, 4, 3, 0, 8, 2, 2, 1, 5,\n",
       "        0, 6, 5, 6, 2, 7, 7, 6, 1, 3, 4, 4, 6, 1, 7, 5, 5, 4, 5, 8, 4, 1, 3, 9,\n",
       "        3, 0, 6, 5, 6, 5, 6, 0, 3, 4, 0, 5, 2, 9, 8, 2], dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec277b66",
   "metadata": {},
   "source": [
    "Create a configurable model that can be hypertuned for the flowers dataset classification\n",
    "\n",
    "Show you can\n",
    "1. Make a hypothesis based on the theory (use the book)\n",
    "1. Design experiments to test your hypothesis\n",
    "1. Work iterative: eg start with a small experiment to get a direction, then reduce the search space and run a more extensive experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc20478",
   "metadata": {},
   "source": [
    "For classifying flowers we need a convolutional neural network because images are high dimensional, nearby pixels are statistically related and if pictures shifts a little al pixels values are different but it is still the same picture. By using a convolutional neural network we make sure we can use weight sharing to deal with the high dimensions, the kernel also takes care of nearby related pixels and takes care of recognizing the geomtric transformations. There are multiple architectures to choose from like LeNet, AlexNet (8 layers), VGG (19 layers), GoogLeNet (22 layers, inception), ResNet(152 layers, skip layers), SqueezeNet (less parameters, 50x less then alexnet). I am working on a simple laptop with cpu so i would like the model which is trained te fastest.   \n",
    "\n",
    "Hypothesis\n",
    "- Increasing the number of batchnorm layers increases the accuracy of the TestCNN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca19b0",
   "metadata": {},
   "source": [
    "settings, trainer, ml flow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60e04742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from typing import List\n",
    "\n",
    "# make a CNN class\n",
    "class TestCNN(nn.Module):\n",
    "    # initialise class\n",
    "    def __init__(self, num_classes: int, filters: int, dropout: float) -> None:\n",
    "        # inherent functions from module\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "                nn.Conv2d(1, filters, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "\n",
    "                nn.Conv2d(filters, filters, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "        \n",
    "                nn.Conv2d(filters, filters, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),       \n",
    "        )\n",
    "        self.agg = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters, filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = dropout),\n",
    "            nn.Linear(filters, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = self.agg(x)\n",
    "            x = self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a1fd6",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194704b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:c:/Users/tycoh/Desktop/MADS-ML-Tyco/4-hypertuning-ray/mlruns/1', creation_time=1761489130988, experiment_id='1', last_update_time=1761489130988, lifecycle_stage='active', name='exercise_4', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment = \"exercise_4\"\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41692e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-28 20:42:13.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20251028-204213\u001b[0m\n",
      "\u001b[32m2025-10-28 20:42:13.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:01<00:00, 30.64it/s]\n",
      "\u001b[32m2025-10-28 20:42:15.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.2202 test 1.8888 metric ['0.3653']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:02<00:00, 24.99it/s]\n",
      "\u001b[32m2025-10-28 20:42:18.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.5027 test 1.1760 metric ['0.5587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2/2 [00:05<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "import torch.optim as optim\n",
    "\n",
    "with mlflow.start_run():\n",
    "    settings = TrainerSettings(\n",
    "        epochs=2,\n",
    "        metrics=[metrics.Accuracy()],\n",
    "        logdir='modellogs',\n",
    "        train_steps= 50,\n",
    "        valid_steps= 50,\n",
    "        reporttypes=[ReportTypes.MLFLOW]\n",
    "    )\n",
    "    \n",
    "    loss_fn =nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    dropout = 0.5\n",
    "    model = TestCNN(num_classes=10, filters = 32, dropout=dropout)\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"epochs\": settings.epochs,\n",
    "        \"metrics\": settings.metrics,\n",
    "        \"train_steps\": settings.train_steps,\n",
    "        \"valid_steps\": settings.valid_steps,\n",
    "        \"dropout\": dropout,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"scheduler\": scheduler\n",
    "    })\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    trainer.loop()\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f06f",
   "metadata": {},
   "source": [
    "Hypothesis\n",
    "- Model has an increase in accuracy by using dropout regularization because this makes the model less dependent on any given hidden unit and encourages weights to have smaller magnitudes and therefore not overfit and thus generalize better\n",
    "\n",
    "Experiment\n",
    "- We set a seed so it is an isolated experiment with na randomness\n",
    "- First, we run 3 epochs for quick testing with TestCNN to examine accuracy with dropout set to 0.0\n",
    "- Next, we run 3 epochs for quick testing with TestCNN with dropout set to 0.5 and examine the results\n",
    "- Lastly, we run 3 epochs for quick testing with TestCNN with dropout set to 1 and examine the results\n",
    "\n",
    "Results\n",
    "- Dropout 0.0 gives max accuracy 0.48\n",
    "- Dropout 0.5 gives max accuracy 0.46\n",
    "- Dropout 1.0 gives max accuracy 0.21\n",
    "\n",
    "Conclusion\n",
    "- Without dropout the model has the best performance. This rejects the hypothesis that it should generalize better with dropout. I believe this is a bad experiment, because this does not match with the theory (which has been tested as well). Dropout is used to prevent overfitting and this simple CNN with a low number of filters is not yet overfitting. I am therefore using regularisation on a model that is not yet performing very well and therefore making the model worse. The next experiment should be focussed on an overfitting CNN and then trying out dropout to increase increase accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fcba3",
   "metadata": {},
   "source": [
    "Hypothesis 2\n",
    "- Adding dropout should increase accuracy on an overfitted CNN\n",
    "\n",
    "Experiment\n",
    "- train an CNN till it is overfitting with dropout 0.0 and check accuracy\n",
    "- train an overfitting CNN, add dropout 0.2 and check accuracy\n",
    "- train an overfitting CNN, add dropout 0.5 and check accuracy\n",
    "\n",
    "Results\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b280e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-28 21:07:51.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20251028-210751\u001b[0m\n",
      "\u001b[32m2025-10-28 21:07:51.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "import torch.optim as optim\n",
    "\n",
    "with mlflow.start_run():\n",
    "    settings = TrainerSettings(\n",
    "        epochs=20,\n",
    "        metrics=[metrics.Accuracy()],\n",
    "        logdir='modellogs',\n",
    "        train_steps= 50,\n",
    "        valid_steps= 50,\n",
    "        reporttypes=[ReportTypes.MLFLOW]\n",
    "    )\n",
    "    \n",
    "    loss_fn =nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    dropout = 0.0\n",
    "    model = TestCNN(num_classes=10, filters=512, dropout=dropout)\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"epochs\": settings.epochs,\n",
    "        \"metrics\": settings.metrics,\n",
    "        \"train_steps\": settings.train_steps,\n",
    "        \"valid_steps\": settings.valid_steps,\n",
    "        \"dropout\": dropout,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"scheduler\": scheduler\n",
    "    })\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    trainer.loop()\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abfb8dc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m modeldir = \u001b[43mPath\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m).resolve()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m modeldir.exists():\n\u001b[32m      3\u001b[39m     modeldir.mkdir()\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "modeldir = Path(\"models\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir()\n",
    "    print(f\"Created {modeldir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91983032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import metrics, Trainer, TrainerSettings, ReportTypes\n",
    "from datetime import datetime\n",
    "from mltrainer.imagemodels import CNNConfig, CNNblocks\n",
    "\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=modeldir,\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.MLFLOW, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params):\n",
    "    # Start a new MLflow run for tracking the experiment\n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", \"cnn\")\n",
    "        # Log hyperparameters to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"batchsize\", f\"{batchsize}\")\n",
    "\n",
    "\n",
    "        # Initialize the optimizer, loss function, and accuracy metric\n",
    "\n",
    "        config = CNNConfig(\n",
    "            matrixshape = (224, 224), # every image is 224x224\n",
    "            batchsize = batchsize,\n",
    "            input_channels = 3, \n",
    "            hidden = params[\"filters\"], \n",
    "            kernel_size = params[\"kernel_size\"],\n",
    "            maxpool = 3, # kernel size of the maxpool\n",
    "            num_layers = params[\"num_layers\"], \n",
    "            num_classes = 5,\n",
    "        )\n",
    "\n",
    "        # Instantiate the CNN model with the given hyperparameters\n",
    "        model = CNNblocks(config)\n",
    "        # Train the model using a custom train loop\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        # Save the trained model with a timestamp\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)\n",
    "\n",
    "        # Log the saved model as an artifact in MLflow\n",
    "        mlflow.log_artifact(local_path=modelpath, artifact_path=\"pytorch_models\")\n",
    "        return {'loss' : trainer.test_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "search_space = {\n",
    "    'filters' : scope.int(hp.quniform('filters', 16, 128, 8)),\n",
    "    'kernel_size' : scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'num_layers' : scope.int(hp.quniform('num_layers', 1, 10, 1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 12544                        \n",
      "Caluclated flatten size: 1304576                     \n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-26 16:25:43.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to C:\\Users\\tycoh\\Desktop\\MADS-ML-Tyco\\4-hypertuning-ray\\models\\20251026-162543\u001b[0m\n",
      "\u001b[32m2025-10-26 16:25:43.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/3 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m1         \u001b[0m| 1/100 [00:30<51:07, 30.98s/it]\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m2         \u001b[0m| 2/100 [00:58<46:53, 28.71s/it]\u001b[A\n",
      "  3%|\u001b[38;2;30;71;6m3         \u001b[0m| 3/100 [01:21<42:32, 26.32s/it]\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m4         \u001b[0m| 4/100 [01:44<40:13, 25.14s/it]\u001b[A\n",
      "  5%|\u001b[38;2;30;71;6m5         \u001b[0m| 5/100 [02:08<39:00, 24.64s/it]\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m6         \u001b[0m| 6/100 [02:32<38:09, 24.36s/it]\u001b[A\n",
      "  7%|\u001b[38;2;30;71;6m7         \u001b[0m| 7/100 [02:56<37:30, 24.20s/it]\u001b[A\n",
      "  8%|\u001b[38;2;30;71;6m8         \u001b[0m| 8/100 [03:20<36:51, 24.04s/it]\u001b[A\n",
      "  9%|\u001b[38;2;30;71;6m9         \u001b[0m| 9/100 [03:44<36:27, 24.04s/it]\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m#         \u001b[0m| 10/100 [04:06<35:19, 23.55s/it]\u001b[A\n",
      " 11%|\u001b[38;2;30;71;6m#1        \u001b[0m| 11/100 [04:30<34:54, 23.53s/it]\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m#2        \u001b[0m| 12/100 [04:54<34:58, 23.85s/it]\u001b[A\n",
      " 13%|\u001b[38;2;30;71;6m#3        \u001b[0m| 13/100 [05:18<34:34, 23.84s/it]\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m#4        \u001b[0m| 14/100 [05:41<33:48, 23.59s/it]\u001b[A\n",
      " 15%|\u001b[38;2;30;71;6m#5        \u001b[0m| 15/100 [06:05<33:33, 23.69s/it]\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m#6        \u001b[0m| 16/100 [06:29<33:26, 23.89s/it]\u001b[A\n",
      " 17%|\u001b[38;2;30;71;6m#7        \u001b[0m| 17/100 [06:53<33:09, 23.97s/it]\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m#8        \u001b[0m| 18/100 [07:16<32:22, 23.68s/it]\u001b[A\n",
      " 19%|\u001b[38;2;30;71;6m#9        \u001b[0m| 19/100 [07:39<31:31, 23.35s/it]\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m##        \u001b[0m| 20/100 [08:02<31:08, 23.35s/it]\u001b[A\n",
      " 21%|\u001b[38;2;30;71;6m##1       \u001b[0m| 21/100 [08:26<30:55, 23.49s/it]\u001b[A\n",
      " 22%|\u001b[38;2;30;71;6m##2       \u001b[0m| 22/100 [08:49<30:21, 23.35s/it]\u001b[A\n",
      " 23%|\u001b[38;2;30;71;6m##3       \u001b[0m| 23/100 [09:12<29:50, 23.25s/it]\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m##4       \u001b[0m| 24/100 [09:36<29:38, 23.40s/it]\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m##5       \u001b[0m| 25/100 [09:59<29:15, 23.40s/it]\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m##6       \u001b[0m| 26/100 [10:23<28:55, 23.45s/it]\u001b[A\n",
      " 27%|\u001b[38;2;30;71;6m##7       \u001b[0m| 27/100 [10:46<28:21, 23.31s/it]\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m##8       \u001b[0m| 28/100 [11:10<28:14, 23.54s/it]\u001b[A\n",
      " 29%|\u001b[38;2;30;71;6m##9       \u001b[0m| 29/100 [11:32<27:26, 23.19s/it]\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m###       \u001b[0m| 30/100 [11:56<27:04, 23.21s/it]\u001b[A\n",
      " 31%|\u001b[38;2;30;71;6m###1      \u001b[0m| 31/100 [12:18<26:19, 22.89s/it]\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m###2      \u001b[0m| 32/100 [12:41<26:11, 23.11s/it]\u001b[A\n",
      " 33%|\u001b[38;2;30;71;6m###3      \u001b[0m| 33/100 [13:05<26:04, 23.35s/it]\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m###4      \u001b[0m| 34/100 [13:28<25:31, 23.21s/it]\u001b[A\n",
      " 35%|\u001b[38;2;30;71;6m###5      \u001b[0m| 35/100 [13:51<25:09, 23.22s/it]\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m###6      \u001b[0m| 36/100 [14:15<24:52, 23.32s/it]\u001b[A\n",
      " 37%|\u001b[38;2;30;71;6m###7      \u001b[0m| 37/100 [14:38<24:29, 23.32s/it]\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m###8      \u001b[0m| 38/100 [15:01<23:58, 23.20s/it]\u001b[A\n",
      " 39%|\u001b[38;2;30;71;6m###9      \u001b[0m| 39/100 [15:24<23:36, 23.22s/it]\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m####      \u001b[0m| 40/100 [15:47<23:06, 23.11s/it]\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m####1     \u001b[0m| 41/100 [16:10<22:42, 23.10s/it]\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m####2     \u001b[0m| 42/100 [16:34<22:20, 23.11s/it]\u001b[A\n",
      " 43%|\u001b[38;2;30;71;6m####3     \u001b[0m| 43/100 [17:05<24:22, 25.67s/it]\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m####4     \u001b[0m| 44/100 [18:48<45:32, 48.80s/it]\u001b[A\n",
      " 45%|\u001b[38;2;30;71;6m####5     \u001b[0m| 45/100 [20:29<59:05, 64.47s/it]\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m####6     \u001b[0m| 46/100 [22:11<1:08:12, 75.80s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=3,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a270b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbest_result\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'best_result' is not defined"
     ]
    }
   ],
   "source": [
    "best_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
